{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social-Media-ZS-final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSASEmjxFqJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPORT ALL THE NECESSARY LIBRARIES\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import datetime\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8rMohdgGQ4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ceb5ce94-78a1-4df7-87e0-20052b436b96"
      },
      "source": [
        "#INSTALLING ALL THE REQUIRED DEPEDANCIES OF NLTK NEEDED FOR OUR PROGRAM \n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9NCAcO9GRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING AN OBJECT FOR STEMMING\n",
        "st = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDxMXfSTGL5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING AN OBJECT FOR LEMMATIZATION \n",
        "lemmatizer = WordNetLemmatizer() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwfOKSwoGPJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING A SET OF ALL STOP WORDS\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC2uJzKsHQ08",
        "colab_type": "code",
        "outputId": "196b6f32-a97f-40fe-fde3-b2aac4594f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "#READING THE TRAIN AND TEST FILES\n",
        "df = pd.read_csv(\"train_file.csv\")\n",
        "df_test = pd.read_csv(\"test_file.csv\")\n",
        "\n",
        "#DISPLAYING THE FIRST 5 ROWS OF THE TRAIN FILE \n",
        "df.head(5)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>Title</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>PublishDate</th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tr3CMgRv1N</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
              "      <td>USA TODAY</td>\n",
              "      <td>obama</td>\n",
              "      <td>2002-04-02 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wc81vGp8qZ</td>\n",
              "      <td>A Look at the Health of the Chinese Economy</td>\n",
              "      <td>Tim Haywood, investment director business-unit...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2008-09-20 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>-0.156386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zNGH03CrZH</td>\n",
              "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
              "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>economy</td>\n",
              "      <td>2012-01-28 00:00:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.425210</td>\n",
              "      <td>0.139754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3sM1H0W8ts</td>\n",
              "      <td>Finland GDP Expands In Q4</td>\n",
              "      <td>Finland's economy expanded marginally in the t...</td>\n",
              "      <td>RTT News</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:06:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wUbnxgvqaZ</td>\n",
              "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
              "      <td>Tourism and public spending continued to boost...</td>\n",
              "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
              "      <td>economy</td>\n",
              "      <td>2015-03-01 00:11:00</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       IDLink  ... SentimentHeadline\n",
              "0  Tr3CMgRv1N  ...         -0.053300\n",
              "1  Wc81vGp8qZ  ...         -0.156386\n",
              "2  zNGH03CrZH  ...          0.139754\n",
              "3  3sM1H0W8ts  ...          0.026064\n",
              "4  wUbnxgvqaZ  ...          0.141084\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiGymAZQJXV8",
        "colab_type": "code",
        "outputId": "3e828fc6-272d-419f-a4a2-fed32fb25757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#OBTAINING THE INFORMATION ABOUT THE VARIOUS COLUMNS OF THE DATASET\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 55932 entries, 0 to 55931\n",
            "Data columns (total 11 columns):\n",
            "IDLink               55932 non-null object\n",
            "Title                55932 non-null object\n",
            "Headline             55932 non-null object\n",
            "Source               55757 non-null object\n",
            "Topic                55932 non-null object\n",
            "PublishDate          55932 non-null object\n",
            "Facebook             55932 non-null int64\n",
            "GooglePlus           55932 non-null int64\n",
            "LinkedIn             55932 non-null int64\n",
            "SentimentTitle       55932 non-null float64\n",
            "SentimentHeadline    55932 non-null float64\n",
            "dtypes: float64(2), int64(3), object(6)\n",
            "memory usage: 4.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h0gRj6SJaip",
        "colab_type": "code",
        "outputId": "4a9e96a5-8e80-4487-dc30-3557d359e31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#UNDERSTANING THE VARIOUS FEATURES OF THE DATASET SUCH AS THE MEAN, MEDIAN AND MODE\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>55932.000000</td>\n",
              "      <td>55932.000000</td>\n",
              "      <td>55932.000000</td>\n",
              "      <td>55932.000000</td>\n",
              "      <td>55932.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>132.050329</td>\n",
              "      <td>4.551616</td>\n",
              "      <td>14.300132</td>\n",
              "      <td>-0.006318</td>\n",
              "      <td>-0.029577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>722.931314</td>\n",
              "      <td>21.137177</td>\n",
              "      <td>76.651420</td>\n",
              "      <td>0.137569</td>\n",
              "      <td>0.143038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.838525</td>\n",
              "      <td>-0.755355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.079057</td>\n",
              "      <td>-0.116927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.027277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.063969</td>\n",
              "      <td>0.057354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>49211.000000</td>\n",
              "      <td>1267.000000</td>\n",
              "      <td>3716.000000</td>\n",
              "      <td>0.962354</td>\n",
              "      <td>0.964646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Facebook    GooglePlus  ...  SentimentTitle  SentimentHeadline\n",
              "count  55932.000000  55932.000000  ...    55932.000000       55932.000000\n",
              "mean     132.050329      4.551616  ...       -0.006318          -0.029577\n",
              "std      722.931314     21.137177  ...        0.137569           0.143038\n",
              "min       -1.000000     -1.000000  ...       -0.838525          -0.755355\n",
              "25%        0.000000      0.000000  ...       -0.079057          -0.116927\n",
              "50%        6.000000      0.000000  ...        0.000000          -0.027277\n",
              "75%       37.000000      2.000000  ...        0.063969           0.057354\n",
              "max    49211.000000   1267.000000  ...        0.962354           0.964646\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK1zZ6WYHd0V",
        "colab_type": "code",
        "outputId": "006c0fbe-f85b-41d1-ae3c-0b632dee6e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#CREATING A TABLE IN ORDER TO UNDERSTAND THE WHICH COLUMNS HAVE NULL VALUES IN THEM\n",
        "#ARRANGING THE VALUES IN DECENDING ORDER IN ORDER TO GET A FAIR IDEA OF THE COLUMN WITH THE MOST NULL VALUES\n",
        "\n",
        "total = df.isnull().sum().sort_values(ascending=False)\n",
        "percent_1 = df.isnull().sum()/df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
        "missing_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Source</th>\n",
              "      <td>175</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SentimentHeadline</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SentimentTitle</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinkedIn</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GooglePlus</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Facebook</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PublishDate</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Headline</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IDLink</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Total    %\n",
              "Source               175  0.3\n",
              "SentimentHeadline      0  0.0\n",
              "SentimentTitle         0  0.0\n",
              "LinkedIn               0  0.0\n",
              "GooglePlus             0  0.0\n",
              "Facebook               0  0.0\n",
              "PublishDate            0  0.0\n",
              "Topic                  0  0.0\n",
              "Headline               0  0.0\n",
              "Title                  0  0.0\n",
              "IDLink                 0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPv1vryxAs8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e86ad469-2fdd-47bb-de6f-e87a25891a3d"
      },
      "source": [
        "#FINDING THE MODE OF THE SOURCE COLUMN \n",
        "df['Source'].mode()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Bloomberg\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk909tuUIEml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#REPLACING THE NULL VALUES WITH THE MODE VALUE IN BOTH TRAIN AND TEST DATASET\n",
        "\n",
        "df['Source']=df['Source'].fillna(\"Bloomberg\")\n",
        "df_test['Source']=df_test['Source'].fillna(\"Bloomberg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wYUpgaFPo7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA PRE-PROCESSING PART\n",
        "\n",
        "replace_puncts = {'`': \"'\", '′': \"'\", '“':'\"', '”': '\"', '‘': \"'\"}\n",
        "\n",
        "strip_chars = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '[', ']', '>', '=', '+', '\\\\', '•',  '~', '@', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "puncts = ['!', '?', '$', '&', '/', '%', '#', '*','£']\n",
        "\n",
        "#FUNCTION FOR CLEANING THE STRING PASSED TO IT \n",
        "def clean_str(x):\n",
        "    x = str(x)\n",
        "    \n",
        "    #CONVERTING ALL THE VALUES TO LOWERCASE \n",
        "    x = x.lower()\n",
        "    \n",
        "    x = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\", \"url\", x)\n",
        "    \n",
        "    for k, v in replace_puncts.items():\n",
        "        x = x.replace(k, f' {v} ')\n",
        "        \n",
        "    for punct in strip_chars:\n",
        "        x = x.replace(punct, ' ') \n",
        "    \n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, ' ')\n",
        "        \n",
        "    x = x.replace(\" '\", \" \")\n",
        "    x = x.replace(\"' \", \" \")\n",
        "        \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypEkwL6jfvbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLEANING THE TITLE COLUMN OF THE TRAINING DATASET\n",
        "\n",
        "save=[] \n",
        "count=1\n",
        "for i in df['Title']:\n",
        "  word_tokens = word_tokenize(i)\n",
        "  filtered_sentence = []\n",
        "  store=[]\n",
        "  for w in word_tokens:\n",
        "        if w not in stop_words: #REMOVAL OF STOP WORDS\n",
        "          w_lem=st.stem(w) #LEMMATIZING THE WORDS\n",
        "          filtered_sentence.append(w_lem) \n",
        "  new_string=\" \".join(filtered_sentence)\n",
        "  i=new_string\n",
        "  store.append(i)\n",
        "  save.append(store)\n",
        "\n",
        "#CREATING A NEW COLUMN IN THE DATAFRAME WHICH IS THE CLEANED VERSION OF THE TITLE COLUMN \n",
        "df['new_Title']=save \n",
        "df['new_Title'] = df['new_Title'].apply(clean_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ9KjVsPWHbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLEANING THE HEADLINE COLUMN OF THE TRAINING DATASET\n",
        "save_head=[]\n",
        "df['Headline'] = df['Headline'].apply(clean_str)\n",
        "\n",
        "for i in df['Headline']:\n",
        "  word_tokens_head = word_tokenize(i)\n",
        "  filtered_sentence_head = []\n",
        "  store=[]\n",
        "  for w in word_tokens_head:\n",
        "        if w not in stop_words: #REMOVAL OF STOP WORDS\n",
        "          w_lem=st.stem(w) #LEMMATIZING THE WORDS\n",
        "          filtered_sentence_head.append(w_lem)\n",
        "  new_string_head=\" \".join(filtered_sentence_head)\n",
        "  i=new_string_head\n",
        "  store.append(i)\n",
        "  save_head.append(store)\n",
        "\n",
        "\n",
        "#CREATING A NEW COLUMN IN THE DATAFRAME WHICH IS THE CLEANED VERSION OF THE HEADLINE COLUMN \n",
        "\n",
        "df['new_headline']=save_head\n",
        "df['new_headline'] = df['new_headline'].apply(clean_str)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-KWGPqkcmi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLEANING THE HEADLINE COLUMN OF THE TEST DATASET\n",
        "save_head=[]\n",
        "df_test['Headline'] = df_test['Headline'].apply(clean_str)\n",
        "\n",
        "for i in df_test['Headline']:\n",
        "  word_tokens_head = word_tokenize(i)\n",
        "  filtered_sentence_head = []\n",
        "  store=[]\n",
        "  for w in word_tokens_head:\n",
        "        if w not in stop_words: #REMOVAL OF STOP WORDS\n",
        "          w_lem=st.stem(w) #LEMMATIZING THE WORDS\n",
        "          filtered_sentence_head.append(w_lem)\n",
        "  new_string_head=\" \".join(filtered_sentence_head)\n",
        "  i=new_string_head\n",
        "  store.append(i)\n",
        "  save_head.append(store)\n",
        "\n",
        "#CREATING A NEW COLUMN IN THE DATAFRAME WHICH IS THE CLEANED VERSION OF THE HEADLINE COLUMN \n",
        "\n",
        "df_test['new_headline']=save_head\n",
        "df_test['new_headline'] = df_test['new_headline'].apply(clean_str)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrJ_eE-kd0zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLEANING THE TITLE COLUMN OF THE TEST DATASET\n",
        "\n",
        "save_head=[]\n",
        "df_test['Title'] = df_test['Title'].apply(clean_str)\n",
        "\n",
        "for i in df_test['Title']:\n",
        "\n",
        "  word_tokens_head = word_tokenize(i)\n",
        "  filtered_sentence_head = [w for w in word_tokens_head if not w in stop_words]\n",
        "\n",
        "  filtered_sentence_head = []\n",
        "  store=[]\n",
        "  for w in word_tokens_head:\n",
        "        if w not in stop_words: #REMOVAL OF STOP WORDS\n",
        "          w_lem=st.stem(w) #LEMMATIZING THE WORDS\n",
        "          filtered_sentence_head.append(w_lem)\n",
        "  new_string_head=\" \".join(filtered_sentence_head)\n",
        "  # new_string_lem=lemmatizer.lemmatize(new_string)\n",
        "  i=new_string_head\n",
        "\n",
        "  store.append(i)\n",
        "  save_head.append(store)\n",
        "\n",
        "#CREATING A NEW COLUMN IN THE DATAFRAME WHICH IS THE CLEANED VERSION OF THE TITLE COLUMN \n",
        "df_test['new_Title']=save_head\n",
        "df_test['new_Title'] = df_test['Title'].apply(clean_str)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_Ah708Po5-",
        "colab_type": "code",
        "outputId": "76097605-cd61-4e44-80cf-9064ae184026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#CATEGORICAL TO NUMBERICAL CONVERSION OF THE COLUMN TOPIC \n",
        "\n",
        "#FOR TRAIN DATASET\n",
        "save_topic=df[\"Topic\"].unique()\n",
        "topic_dict={}\n",
        "count=1\n",
        "for i in save_topic:\n",
        "  topic_dict[i]=count\n",
        "  count=count+1\n",
        "\n",
        "print(topic_dict)\n",
        "\n",
        "#REPLACING\n",
        "for i in topic_dict:\n",
        "  df=df.replace(to_replace=i,value=topic_dict[i])\n",
        "\n",
        "#FOR TESTING DATASET\n",
        "\n",
        "save_topic_test=df_test[\"Topic\"].unique()\n",
        "topic_dict_test={}\n",
        "count=1\n",
        "for i in save_topic_test:\n",
        "  topic_dict_test[i]=count\n",
        "  count=count+1\n",
        "\n",
        "print(topic_dict_test)\n",
        "\n",
        "#REPLACING\n",
        "for i in topic_dict_test:\n",
        "  df_test=df_test.replace(to_replace=i,value=topic_dict_test[i])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'obama': 1, 'economy': 2, 'microsoft': 3, 'palestine': 4}\n",
            "{'economy': 1, 'microsoft': 2, 'obama': 3, 'palestine': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nclQVDC6Po1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPLITTING THE DATE AND TIME COLUMNS IN ORDER TO OBTAIN THE HOUR AND DAY FROM IT \n",
        "\n",
        "df_day = []\n",
        "df_test_day = []\n",
        "\n",
        "for i in df['PublishDate']:\n",
        "    df_day.append(datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\"))\n",
        "    \n",
        "for i in df_test['PublishDate']:\n",
        "    df_test_day.append(datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\"))\n",
        "\n",
        "df['day'] = df_day\n",
        "df_test['day'] = df_test_day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0H0IVuHF-Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MAPPING THE DAYS OF THE WEEK TO NUMERIC VALUES \n",
        "\n",
        "#FOR TRAINING DATASET\n",
        "df['day'] = df['day'].map({'Monday': 0,\n",
        "                                        'Tuesday': 1,\n",
        "                                        'Wednesday': 2,\n",
        "                                        'Thursday': 3,\n",
        "                                        'Friday': 4,\n",
        "                                        'Saturday': 5,\n",
        "                                        'Sunday': 6})\n",
        "\n",
        "#FOR TESTING DATASET\n",
        "df_test['day'] = df_test['day'].map({'Monday': 0,\n",
        "                                        'Tuesday': 1,\n",
        "                                        'Wednesday': 2,\n",
        "                                        'Thursday': 3,\n",
        "                                        'Friday': 4,\n",
        "                                        'Saturday': 5,\n",
        "                                        'Sunday': 6})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOoDCpPxTOkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXTRACTING THE HOUR FROM THE PUBLISH DATE COLUMN\n",
        "\n",
        "df[\"hour\"] = df[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])\n",
        "df_test[\"hour\"] = df_test[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeEcNPSHIWww",
        "colab_type": "code",
        "outputId": "528c13a9-c1d0-40e9-a1b2-480f131a05cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#CHECKING FOR ALL THE NEW COLUMNS CREATED\n",
        "\n",
        "df.columns\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['IDLink', 'Title', 'Headline', 'Source', 'Topic', 'PublishDate',\n",
              "       'Facebook', 'GooglePlus', 'LinkedIn', 'SentimentTitle',\n",
              "       'SentimentHeadline', 'new_Title', 'new_headline', 'day', 'hour'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPcQVVglTinh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING A MAPPING FUNCTION WHERE THE NEW_TITLE IS MAPPED WITH TFIDF MODLE TO OBTAIN THE NUMERIC VALUE OF THE STRING\n",
        "#THE REST VALUES ARE MENTIONED AS IT IS SINCE THEY ARE IN THEIR NUMBERIC FORMAT\n",
        "\n",
        "mapper_title = DataFrameMapper([\n",
        "    ('new_Title', TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
        " stop_words= 'english',ngram_range=(1,1))),\n",
        "    ('Facebook', None),\n",
        "    ('GooglePlus', None),\n",
        "    ('LinkedIn', None),\n",
        "\n",
        "], default = False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egILMObZJGKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING A MAPPING FUNCTION WHERE THE NEW_TITLE IS MAPPED WITH TFIDF MODLE TO OBTAIN THE NUMERIC VALUE OF THE STRING\n",
        "#THE REST VALUES ARE MENTIONED AS IT IS SINCE THEY ARE IN THEIR NUMBERIC FORMAT\n",
        "\n",
        "mapper_headline = DataFrameMapper([\n",
        "    ('new_headline', TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
        " stop_words= 'english',ngram_range=(1,1))),\n",
        "    ('Facebook', None),\n",
        "    ('GooglePlus', None),\n",
        "    ('LinkedIn', None),\n",
        "], default = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-EuIETlJVV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OBTAINING THE RELEVANT DATA NEEDED FOR TRAINING-TESTING DATA AND ALSO FOR PREDICTION PURPOSES \n",
        "\n",
        "#FOR TITLE\n",
        "features_title = mapper_title.fit_transform(df)\n",
        "labels_title =df['SentimentTitle']\n",
        "test_features_title = mapper_title.transform(df_test)\n",
        "\n",
        "#FOR HEADLINES\n",
        "features_headline = mapper_headline.fit_transform(df)\n",
        "labels_headline = df['SentimentHeadline']\n",
        "test_features_headline = mapper_headline.transform(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVS_pjieJpdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPLITTING THE DATA INTO TESTING AND TRAINING DATA FOR TITLE \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features_title, labels_title, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmK3N0h0D4G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#APPLYING VARIOUS ALGORITHMS TO CHECK THE EFFICIENCY "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbBdjVXAKDnW",
        "colab_type": "code",
        "outputId": "866c5ea9-0ad4-4f0d-84e2-adf1ef8882f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#LINEAR SVR \n",
        "\n",
        "estimator = LinearSVR(C=0.1)\n",
        "estimator.fit(X_train,Y_train)\n",
        "predictions_svr = estimator.predict(X_test)\n",
        "mae1=mean_absolute_error(Y_test,predictions_svr)\n",
        "print(mae1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08495550229224834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1vcKFiUUGTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f200247-30f0-4d08-e2cd-dd21313883b9"
      },
      "source": [
        "#LASSO REGRESSION \n",
        "\n",
        "clf = linear_model.Lasso(alpha=0.1)\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_prediction = clf.predict(X_test)\n",
        "mae1forLASSO=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae1forLASSO)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0975483356133821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GknjVaUmYkN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d5de1e-132f-4518-bedb-ce7ead3aed67"
      },
      "source": [
        "#RIDGE REGRESSION \n",
        "\n",
        "clf1_t = linear_model.Ridge(alpha=1.0)\n",
        "clf1_t.fit(X_train, Y_train)\n",
        "Y_prediction = clf1_t.predict(X_test)\n",
        "mae1forRIDGE=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae1forRIDGE)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08103896845801914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHtGvr34W6-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1090284-1bbf-41a0-a9c2-4b98e8fd6cc8"
      },
      "source": [
        "#ELASTIC NET \n",
        "\n",
        "regr = ElasticNet(random_state=0)\n",
        "regr.fit(X_train, Y_train)\n",
        "Y_prediction = regr.predict(X_test)\n",
        "mae1forEN=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae1forEN)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09754924503260368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u7o8SXaaq49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac77ed2e-9852-4fd0-a827-ac797629b99b"
      },
      "source": [
        "#DISPLAYING THE RESULTS OBTAINED FOR THE MAE METRIC BY CARRYING OUR VARIOUS ALGORITHMS \n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['LINEAR SVR', 'LASSO', 'RIDGE', \n",
        "              'ELASTIC NET'],\n",
        "    'Score': [mae1, mae1forLASSO, mae1forRIDGE, \n",
        "              mae1forEN]})\n",
        "result_df = results.sort_values(by='Score', ascending=True)\n",
        "result_df = result_df.set_index('Score')\n",
        "result_df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Score</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.081039</th>\n",
              "      <td>RIDGE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.084956</th>\n",
              "      <td>LINEAR SVR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.097548</th>\n",
              "      <td>LASSO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.097549</th>\n",
              "      <td>ELASTIC NET</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model\n",
              "Score                \n",
              "0.081039        RIDGE\n",
              "0.084956   LINEAR SVR\n",
              "0.097548        LASSO\n",
              "0.097549  ELASTIC NET"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjBDxKfWEbzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d0fb977-fc30-4948-f2b8-586d98077cc3"
      },
      "source": [
        "#FINDING THE MINIMUM VALUE OF THE MAE FROM ALL THE AVAILABLE VALUES FOR TITLE \n",
        "min_val_x=results['Score'].min()\n",
        "print(min_val_x)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08103896845801914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD3qvcFgW0GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPLITTING THE DATA INTO TESTING AND TRAINING DATA FOR HEADLINES \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features_headline, labels_headline, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQcLKVtkWnFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LINEAR SVR \n",
        "\n",
        "estimator1 = LinearSVR(C=0.2)\n",
        "estimator1.fit(X_train, Y_train)\n",
        "predictions_svr1 = estimator1.predict(X_test)\n",
        "mae2=mean_absolute_error(Y_test,predictions_svr)\n",
        "print(mae2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7frR8mIaVIQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LASSO REGRESSION \n",
        "\n",
        "clf = linear_model.Lasso(alpha=0.1)\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_prediction = clf.predict(X_test)\n",
        "mae2forLASSO=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae2forLASSO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89sjcUemUImb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RIDGE REGRESSION \n",
        "\n",
        "clf1 = linear_model.Ridge(alpha=1.0)\n",
        "clf1.fit(X_train, Y_train)\n",
        "Y_prediction = clf1.predict(X_test)\n",
        "mae2forRIDGE=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae2forRIDGE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eMGKwG5bS-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ELASTIC NET \n",
        "\n",
        "regr = ElasticNet(random_state=0)\n",
        "regr.fit(X_train, Y_train)\n",
        "Y_prediction = regr.predict(X_test)\n",
        "mae2forEN=mean_absolute_error(Y_test,Y_prediction)\n",
        "print(mae2forEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kDNQgidbWo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DISPLAYING THE RESULTS OBTAINED FOR THE MAE METRIC BY CARRYING OUR VARIOUS ALGORITHMS \n",
        "\n",
        "results1 = pd.DataFrame({\n",
        "    'Model': ['LINEAR SVR', 'LASSO', 'RIDGE', \n",
        "              'ELASTIC NET'],\n",
        "    'Score': [mae2, mae2forLASSO, mae2forRIDGE, \n",
        "              mae2forEN]})\n",
        "result1_df = results1.sort_values(by='Score', ascending=True)\n",
        "result1_df = result1_df.set_index('Score')\n",
        "result1_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-XNwVpwc9QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FINDING THE MINIMUM VALUE OF THE MAE FROM ALL THE AVAILABLE VALUES FOR HEADLINES\n",
        "min_val=results1['Score'].min()\n",
        "print(min_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3lS6QIZWWsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CALCULATING THE LEADERBOARD SCORE BY THE HELP OF THE GIVEN FORMULA \n",
        "\n",
        "Leaderboardscore=max(0,(1 - ((0.4 * min_val_x) + (0.6 * min_val))))\n",
        "print(Leaderboardscore)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HeMmJ2KkiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FINDING THE PREDICTED VALUES BY CONSIDERING THE MOST OPTIMUM ALGO, HERE RIDGE REGRESSION \n",
        "\n",
        "#FOR TITLE\n",
        "clf1_t.fit(features_title, labels_title)\n",
        "final_pred_title = clf1_t.predict(test_features_title)\n",
        "\n",
        "#FOR HEADLINE\n",
        "clf1.fit(features_headline, labels_headline)\n",
        "final_pred_headline = clf1.predict(test_features_headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7LxFGGJRFYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GETTING THE ID FOR THE NEWS, THE TITLE SENTIMENT PREDICTED , THE HEADLINE SENTIMENT PREDICTED\n",
        "final = pd.DataFrame({'IDLink': df_test['IDLink'], 'SentimentTitle': list(final_pred_title), 'SentimentHeadline': list(final_pred_headline)})\n",
        "\n",
        "#COVERTING THE DATAFRAME TO CSV FORMAT FOR SUBMISSION\n",
        "final.to_csv('final-RIDGE.csv',  encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}